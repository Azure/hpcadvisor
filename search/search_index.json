{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HPCAdvisor","text":""},{"location":"#goal","title":"Goal","text":"<p>The goal of this tool is to assist users in selecting a cluster configuration based on actual application executions. Underneath, the execution of the application is based on resources provisioned by Azure Batch; but the data collected can be used to make decisions for other environments including Azure CycleCloud, Azure VMSS, Azure VMs, AKS, etc.</p> <p>For now the tool focuses on testing:</p> <ul> <li>SKUs</li> <li>Number of cluster nodes</li> <li>Processes per node</li> <li>Application input parameters</li> </ul> <p>For next versions we will explore other factors such as storage and gpus in addition to other features related to avoiding scenarios to optimize unnecessary tests.</p>"},{"location":"#operations","title":"Operations","text":"<p>The tool offers three operations:</p> <p>1. Data collector. Run the application under multiple scenarios to collect execution times and other metric data (for now cpu usage).</p> <p>2. Plot generator. Generate several plots considering the collected data, including exec time as a function of skus and number of nodes, cost as a function of skus and number of nodes. In addition, plots all of these metrics as a function of the application input parameters.</p> <p>3. Recommendation generator. Generate the pareto front considering execution time and costs. We leave to the user to make the final decision that balances both metrics, as users may be willing to sacrifice execution time in favor of cost for instance. We also provide as output the best time and best cost.</p> <p>In this code we have examples to run tests with actual applications, including WRF, OpenFOAM, NAMD, and GROMACS. Other apps will become available on the way.</p>"},{"location":"#user-interaction-cligui","title":"User interaction (CLI/GUI)","text":"<p>It also has two execution modes (user interaction), one via CLI (Command Line Interface) and the other via web browser (GUI).</p>"},{"location":"#cli-screenshot","title":"CLI screenshot","text":""},{"location":"#gui-browser-screenshot","title":"GUI (browser) screenshot","text":""},{"location":"#auto-generated-plot","title":"Auto-generated plot","text":"<p>Plots are auto-generated and can be seen in the GUI or as files generated via CLI execution. Here is an example of plot generated for the \"Hello World\" matrix multiplication example.</p>"},{"location":"#auto-generated-advice","title":"Auto-generated advice","text":"<p>Advices are represented as tables, which comes from calculation of the pareto-front considering execution time and costs.</p> <p>Example of output for the \"Hello World\" matrix multiplication example.</p> <pre><code>Generating advice...\nAppinputs: appinteractions=3  appmatrixsize=4000\nExectime(s)  Cost($/h)    Nodes  SKU\n51           0.0898       2      standard_hc44rs\n\nAppinputs: appinteractions=3  appmatrixsize=7000\nExectime(s)  Cost($/h)    Nodes  SKU\n126          0.2218       2      standard_hc44rs\n</code></pre>"},{"location":"commands/","title":"Commands","text":"<p>There are five hpcadvisor commands:</p> <ul> <li><code>deploy</code>: operations related to a deployment</li> <li><code>collect</code>: operation(s) related to data collection (i.e. execution of tasks)</li> <li><code>plot</code>: operation(s) related to generation of plots</li> <li><code>advice</code>: operations(s) related to generation of advice</li> <li><code>gui</code>: trigger of the graphical user interface (gui) via browser</li> </ul> <p>These commands can use the debug mode via <code>-d</code> flag and show help using <code>-h</code>.</p> <p>A deployment is a resource group that contains all computing resources.</p> <p>So in general the usage of the hpcadvisor is gonna be:</p> <pre><code>./hpcadvisor [-d] &lt;command&gt; [ &lt;command parameters&gt; ]\n</code></pre>"},{"location":"commands/#deploy","title":"deploy","text":"<p>Create a new deployment using user input from file (mandatory) and name of the deployment (optional):</p> <pre><code>./hpcadvisor deploy create [-h] [-n NAME] [-u USERINPUT] operation\n\n\noptions:\n  -n NAME, --name NAME  Deployment name\n  -u USERINPUT, --userinput USERINPUT\n                        User input\n</code></pre> <p>List deployments:</p> <pre><code>./hpcadvisor deploy list\n</code></pre> <p>Shutdown a deployment, which means deleting all resources and resource group.</p> <pre><code>./hpcadvisor deploy shutdown -n &lt;name&gt;\n</code></pre>"},{"location":"commands/#collect","title":"collect","text":"<p>Collect data (i.e. run jobs). The option <code>cleardeployment</code> is to delete all resources and resource group once the collection is completed and option <code>cleartasks</code> is to run all new tasks that are created, as some tasks may have already been completed for another data collection operation on the same deployment.</p> <pre><code>./hpcadvisor collect [-h] -n NAME -u USERINPUT [-cd CLEARDEPLOYMENT] [-ct CLEARTASKS]\n\noptions:\n  -n NAME, --name NAME  Deployment name\n  -u USERINPUT, --userinput USERINPUT\n                        User input\n  -cd CLEARDEPLOYMENT, --cleardeployment CLEARDEPLOYMENT\n                        Clear deployment\n  -ct CLEARTASKS, --cleartasks CLEARTASKS\n                        Clear tasks\n</code></pre>"},{"location":"commands/#plot","title":"plot","text":"<p>Generate plots.</p> <pre><code>./hpcadvisor plot [-h] -df DATAFILTER\n\noptions:\n  -df DATAFILTER, --datafilter DATAFILTER\n                        Data filter\n</code></pre>"},{"location":"commands/#advice","title":"advice","text":"<p>Generate advice (pareto-front).</p> <pre><code>hpcadvisor advice [-h] [-n NAME] [-df DATAFILTER]\n\noptions:\n  -n NAME, --name NAME  Deployment name\n  -df DATAFILTER, --datafilter DATAFILTER\n                        Data filter\n</code></pre>"},{"location":"commands/#gui","title":"gui","text":"<p>Run the hpcadvisor using browser (GUI).</p> <pre><code>./hpcadvisor gui [-h] [-u USERINPUT]\n\noptions:\n  -u USERINPUT, --userinput USERINPUT\n                        User input\n</code></pre>"},{"location":"configfiles/","title":"Files and Dirs","text":""},{"location":"configfiles/#ui-defaults","title":"UI defaults","text":"<p>This YAML file is used as input for both CLI and GUI to deploy environments, collect data, plot graphs, and get advice.</p> <p>It currently has these fields:</p> <ul> <li><code>subscription</code>: subscription name used to provision resources</li> <li><code>rgprefix</code>: prefix of resource group name used to host all resources</li> <li><code>region</code>: Azure geographical region of deployment (e.g. eastus,   southcentralus,...)</li> <li><code>appsetupurl</code>: url that contains the bash script with instructions on how to   download input data and application, and how to run the application</li> <li><code>skus</code>: Azure SKUs (VM types) to be tested</li> <li><code>nnodes</code>: Number of nodes to be tested</li> <li><code>ppr</code>: percentage of processes per resource</li> <li><code>appinputs</code>: application inputs (e.g. matrix size and number of execution   interactions for the matrix multiplication application)</li> <li><code>vpnrg</code> (optional): existing resource group that contains a vpn setup</li> <li><code>vpnvnet</code> (optional): existing vnet name for the vpn setup</li> <li><code>peervpn</code> (optional): boolean for peering with vpn resource group / vnet</li> <li><code>createjumpbox</code> (optional): boolean for creating a VM in the same resource group</li> </ul> <p>Example inside matrix multiplication folder:</p> ui_defaults.yaml<pre><code>subscription: mysubscription\nskus: [Standard_HC44rs, Standard_HB120rs_v2, Standard_HB120rs_v3]\nrgprefix: nettoaha\nappsetupurl: https://raw.githubusercontent.com/Azure/hpcadvisor/main/examples/matrixmult/appsetup_matrix.sh\nnnodes: [2, 3, 4]\nappname: matrixmult\ntags:\n  appname: matrixmult\n  version: v1\nregion: southcentralus\ncreatejumpbox: true\nppr: 100\nappinputs:\n  appinteractions: 3\n  appmatrixsize: [4000, 7000]\n</code></pre>"},{"location":"configfiles/#data-filter","title":"Data filter","text":"<p>This YAML file specifies which parts of the dataset one wants to use for plotting graphs or getting advice (pareto-front). You can specify the application name, and the deployment environments, which can be useful in case data was collected using a few deployments but one does not want to consider all deployments for that particular application.</p> <p>Example inside matrix multiplication folder:</p> datafilter_matrixmult.yaml<pre><code>appname: matrixmult\n\n# uncomment to filter more\n\n#deployment: mydeployment240712v1\n#tags:\n#  version: v1\n</code></pre>"},{"location":"configfiles/#main-hpcadvisor-dir","title":"Main HPCAdvisor dir","text":"<p>All files related to deployment, dataset, task output, among others are stored in the main HPCAdvisor folder, located at:</p> <pre><code>$HOME/.hpcadvisor/\n</code></pre>"},{"location":"configfiles/#deployment-dirs","title":"Deployment dirs","text":"<p>Every deployment contains a directory located at:</p> <pre><code>$HOME/.hpcadvisor/&lt;deploymentname&gt;\n</code></pre>"},{"location":"configfiles/#task-stderr-and-stdout","title":"Task stderr and stdout","text":"<p>For each task executed, two files are collected:</p> <p>Standard error and standard output:</p> <pre><code>$HOME/.hpcadvisor/&lt;deploymentname&gt;/output-&lt;taskname&gt;/stderr.txt\n$HOME/.hpcadvisor/&lt;deploymentname&gt;/output-&lt;taskname&gt;/stdout.txt\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Here we have a few examples how to use HPCAdvisor. For each example, we have different mechanisms to setup the application. As the application setup is based on bash script, users can install in different ways, using for instance source code, binary download, easybuild, EESSI, spack, etc..</p> <p>Examples of applications to be tested using hpcadvisor:</p>"},{"location":"examples/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>As a \"Hello World\" example, we are gonna use matrix multiplication application, which receives two parameters: size of the squared matrix (dimension) and number of times such multiplication should happen (e.g. only once, 10 times, 100 times, and so on).</p> <p>The files for this example are in the examples folder which has three files:</p> <ul> <li><code>mpi_matrix_mult.c</code>: source code of the application.</li> <li><code>appsetup_matrix.sh</code>: shell script that downloads the source file, compiles   it, and generates the application run script that will be used for each   execution scenario.</li> <li><code>plotfilter_matrixmult.json</code>: filter to consider only data for this   application when generating the plots and the recommendation (pareto-front   data).</li> <li><code>ui_defaults.yaml</code>: user input to create the environment, setup application,   and define scenarios to be explored.</li> </ul> ui_defaults.yaml<pre><code>subscription: mysubscription\nskus: [Standard_HC44rs, Standard_HB120rs_v2, Standard_HB120rs_v3]\nrgprefix: nettoaha\nappsetupurl: https://raw.githubusercontent.com/Azure/hpcadvisor/main/examples/matrixmult/appsetup_matrix.sh\nnnodes: [2, 3, 4]\nappname: matrixmult\ntags:\n  appname: matrixmult\n  version: v1\nregion: southcentralus\ncreatejumpbox: true\nppr: 100\nappinputs:\n  appinteractions: 3\n  appmatrixsize: [4000, 7000]\n</code></pre>"},{"location":"examples/#wrf","title":"WRF","text":"<p>The Weather Research and Forecasting (WRF) Model is a well known system for meteorologists and researchers to simulate and predict weather patterns at various spatial and temporal scales. WRF can simulate atmospheric processes, including dynamics, thermodynamics, and microphysical processes. The model can be configured for different domains, resolutions, and parameterizations, and it is widely used for benchmarking HPC systems.</p> <p>The example for this app (files here) is based on installation using EESSI.</p>"},{"location":"examples/#gromacs","title":"GROMACS","text":"<p>The GROMACS (GROningen MAchine for Chemical Simulations) project originally began in 1991 at Department of Biophysical Chemistry, University of Groningen, Netherlands. GROMACS is widely used in computational chemistry, biochemistry, and related fields for simulating the behavior of molecules at the atomic level.</p> <p>The example for this app (files here) is based on installation using EESSI.</p>"},{"location":"examples/#openfoam","title":"OpenFOAM","text":"<p>OpenFOAM (Open Field Operation and Manipulation) is a free, open-source computational fluid dynamics (CFD) software package developed by the OpenFOAM Foundation. OpenFOAM has an extensive range of features to solve anything from complex fluid flows involving chemical reactions, turbulence and heat transfer, to acoustics, solid mechanics and electromagnetics. OpenFOAM uses the finite volume method to discretize and solve the governing equations of fluid flow and other related physical phenomena. OpenFOAM is used in several industries including automotive, aerospace, energy, environmental engineering, chemical processing, and academic research. OpenFOAM is professionally released every six months to include customer sponsored developments and contributions from the community. It is written in C++ is modular, which allows customizations.</p> <p>The example for this app (files here) is based on installation using EESSI.</p>"},{"location":"examples/#namd","title":"NAMD","text":"<p>Nanoscale Molecular Dynamics (NAMD) is a parallel molecular dynamics code designed for high-performance simulation of large biomolecular systems, including proteins, nucleic acids, and membranes, at the atomic level over time.It is particularly valuable for understanding processes such as protein folding, biomolecular recognition, and drug binding, among others. NAMD is developed and maintained by the Theoretical and Computational Biophysics Group at the University of Illinois at Urbana-Champaign.</p> <p>The example for this app (files here) is based on installation using the binary from NAMD official website.</p>"},{"location":"examples/#lammps","title":"LAMMPS","text":"<p>Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) is a molecular dynamics simulator designed to model particles in a variety of scientific and engineering applications. Developed by Sandia National Laboratories, it is highly scalable, so one can run it on single processors or in parallel using message-passing techniques. LAMMPS uses spatial-decomposition techniques to partition the simulation domain into small 3D sub-domains, one of which is assigned to each processor.</p> <p>The example for this app (files here) is based on installation using EESSI.</p>"},{"location":"quickstart/","title":"Getting started","text":""},{"location":"quickstart/#setup","title":"Setup","text":"<p>The hpcadvisor setup is based on python poetry to handle dependencies and a python virtual environment.</p> <p>Check poetry installation guidelines HERE. Once poetry is installed run the following commands in your terminal to install and create python virtual environment.</p> <pre><code>git clone https://github.com/Azure/hpcadvisor.git\ncd hpcadvisor\npoetry install\npoetry shell\ncd bin\n</code></pre>"},{"location":"quickstart/#generate-standalone-binary","title":"Generate standalone binary","text":"<p>Alternatively, you can generate a standalone binary file using:</p> <ul> <li>poetry</li> <li>pyinstaller</li> </ul> <p>From project root folder, type:</p> <pre><code>poetry run pyinstaller src/hpcadvisor/__main__.py  --onefile --name hpcadvisor\n</code></pre>"},{"location":"quickstart/#simple-example","title":"Simple example","text":"<p>Follow the matrix multiplication example here for detailed instructions.</p>"},{"location":"quickstart/#cli-based-execution","title":"CLI-based execution","text":"<p>Once the setup above (via poetry) is done, for the matrix multiplication example, you just need to update <code>examples/matrixmult/ui_defaults.json</code> with your preferences. For this example, you only need to update <code>subscription</code>, and you should be good to go.</p> <p>The follow two lines deploy a computing environment specified in ui defaults file and start the data collection (i.e. run the jobs), respectively:</p> <pre><code>./hpcadvisor deploy create -u ../examples/matrixmult/ui_defaults.json\n./hpcadvisor collect -n &lt;deploymentname&gt; -u ../examples/matrixmult/ui_defaults.json\n</code></pre> <p>If you want to only test the plot generator component, skipping the data collection, you need to copy a dataset file to hpcadvisor directory:</p> <pre><code>mkdir $HOME/.hpcadvisor/\ncp ../examples/matrixmult/dataset.json $HOME/.hpcadvisor/\n</code></pre> <p>Then request the plot generation:</p> <pre><code>./hpcadvisor plot -df ../examples/matrixmult/plotfilter_matrixmult.json\n</code></pre> <p>To get the advice (based on pareto-front calculation):</p> <pre><code>./hpcadvisor advice -df examples/matrixmult/plotfilter_matrixmult.json\n</code></pre>"},{"location":"quickstart/#gui-based-execution","title":"GUI-based execution","text":"<p>One can use the browser version and click the buttons for the different operations. To pre-fill user input, specify the input file as showed below:</p> <pre><code>./hpcadvisor gui -u ../examples/matrixmult/ui_defaults.json\n</code></pre>"}]}